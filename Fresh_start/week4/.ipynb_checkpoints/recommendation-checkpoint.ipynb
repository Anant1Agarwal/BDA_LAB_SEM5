{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f81c8a0-e41e-4691-84b8-a5f308ad4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "230b94ea-881c-46bf-92ff-376d0ca8f0ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:52:41 WARN Utils: Your hostname, Anants-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 10.86.5.30 instead (on interface en0)\n",
      "24/11/05 18:52:41 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/05 18:52:42 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark=SparkSession.builder.appName(\"Recommender\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595b58fb-8786-4588-8cc4-609b84996593",
   "metadata": {},
   "source": [
    "1) Demonstrate how to load a dataset suitable for recommendation systems into a PySpark DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c05dbf00-6a84-4886-9cf1-0c252e483945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+\n",
      "|User-ID|      ISBN|Book-Rating|\n",
      "+-------+----------+-----------+\n",
      "| 276725|034545104X|          0|\n",
      "| 276726|0155061224|          5|\n",
      "| 276727|0446520802|          0|\n",
      "| 276729|052165615X|          3|\n",
      "| 276729|0521795028|          6|\n",
      "| 276733|2080674722|          0|\n",
      "| 276736|3257224281|          8|\n",
      "| 276737|0600570967|          6|\n",
      "| 276744|038550120X|          7|\n",
      "| 276745| 342310538|         10|\n",
      "| 276746|0425115801|          0|\n",
      "| 276746|0449006522|          0|\n",
      "| 276746|0553561618|          0|\n",
      "| 276746|055356451X|          0|\n",
      "| 276746|0786013990|          0|\n",
      "| 276746|0786014512|          0|\n",
      "| 276747|0060517794|          9|\n",
      "| 276747|0451192001|          0|\n",
      "| 276747|0609801279|          0|\n",
      "| 276747|0671537458|          9|\n",
      "+-------+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df=spark.read.options(delimiter=\";\", header=True, inferSchema=True).csv(\"ratings.csv\")\n",
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c19f75b3-51a2-4a32-a834-93b4f70ebffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:=======>                                                   (1 + 7) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------+------------------+\n",
      "|summary|           User-ID|       ISBN|       Book-Rating|\n",
      "+-------+------------------+-----------+------------------+\n",
      "|  count|           1149780|    1149780|           1149780|\n",
      "|   mean|140386.39512602412|   Infinity|2.8669501991685364|\n",
      "| stddev| 80562.27771851176|        NaN| 3.854183859201656|\n",
      "|    min|                 2| 0330299891|                 0|\n",
      "|    max|            278854| ï¿½423350229|                10|\n",
      "+-------+------------------+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "rating_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828c1b37-d04a-4044-b64e-a13f4114f40b",
   "metadata": {},
   "source": [
    "2) Implement a PySpark script that splits the data and trains a recommendation model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20957dd1-ef47-4750-84b6-f102fd502fbb",
   "metadata": {},
   "source": [
    "Preprocessing data to be fed into ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8c0d284-c78c-4bc8-8186-2d3cd6e7574a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "user_Indexer=StringIndexer(inputCol=\"User-ID\",outputCol=\"User-ID-numeric\")\n",
    "item_Indexer=StringIndexer(inputCol=\"ISBN\",outputCol=\"ISBN-numeric\")\n",
    "\n",
    "user_indexer_model = user_Indexer.fit(df)\n",
    "item_indexer_model = item_Indexer.fit(df)\n",
    "\n",
    "rating_df=user_indexer_model.transform(df)\n",
    "\n",
    "rating_df=item_indexer_model.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376724bc-647e-4535-b47d-6893376181bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=rating_df.randomSplit([0.7,0.3],seed=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf146d-c133-4ef3-bb67-0b0b3748d6e4",
   "metadata": {},
   "source": [
    "3) Implement a PySpark script using the ALS algorithm for collaborative filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "514e8e08-3665-4b67-bc7a-ddeeaa7c4589",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:52:52 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "[Stage 12:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+---------------+------------+\n",
      "|User-ID|      ISBN|Book-Rating|User-ID-numeric|ISBN-numeric|\n",
      "+-------+----------+-----------+---------------+------------+\n",
      "|      2|0195153448|          0|        69494.0|    160911.0|\n",
      "|      7| 034542252|          0|        98245.0|     93830.0|\n",
      "|      8|0060973129|          0|         7987.0|     58687.0|\n",
      "|      8|0374157065|          0|         7987.0|     14866.0|\n",
      "|      8|0393045218|          0|         7987.0|    185208.0|\n",
      "+-------+----------+-----------+---------------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c9ddf0c-4a0a-4b96-ad63-0b9e8bd8b8a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:52:53 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:52:54 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:52:56 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:52:57 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "24/11/05 18:52:58 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:01 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:02 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:05 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:06 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/11/05 18:53:06 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/11/05 18:53:07 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:07 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "24/11/05 18:53:08 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:09 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:11 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:12 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:13 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:14 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:15 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:17 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:18 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:19 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:21 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:22 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:23 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:25 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:26 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:27 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:29 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:30 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:31 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:33 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "als=ALS(maxIter=10,regParam=0.01, userCol=\"User-ID-numeric\",itemCol=\"ISBN-numeric\",ratingCol=\"Book-Rating\",coldStartStrategy=\"drop\")\n",
    "model=als.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b76050-b42e-4079-9770-1bca73bb234c",
   "metadata": {},
   "source": [
    "4) Implement code to evaluate the performance of the recommendation model using appropriate metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d61f6ee0-601d-4c52-95ed-3e0842181ead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:53:35 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:35 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:36 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:41 WARN DAGScheduler: Broadcasting large task binary with size 5.1 MiB\n",
      "24/11/05 18:53:42 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+---------------+------------+-----------+\n",
      "|User-ID|      ISBN|Book-Rating|User-ID-numeric|ISBN-numeric| prediction|\n",
      "+-------+----------+-----------+---------------+------------+-----------+\n",
      "| 278144|0446605239|          0|         2173.0|        26.0|        0.0|\n",
      "|  18433|0446605239|          9|        37755.0|        26.0|-0.23881508|\n",
      "|  29259|0446605239|          0|          222.0|        26.0| -1.8786317|\n",
      "| 278543|0446605239|          5|        21939.0|        26.0|   7.625286|\n",
      "|  17950|0446605239|          6|          339.0|        26.0|  3.1203241|\n",
      "|  18082|0446605239|          9|         1499.0|        26.0| 0.20222846|\n",
      "|   9391|0446605239|          0|        45808.0|        26.0|        0.0|\n",
      "|  35859|0446605239|          0|            4.0|        26.0|  1.2179252|\n",
      "|  26535|0446605239|          0|          167.0|        26.0|  4.5420933|\n",
      "|  31315|0446605239|          0|           83.0|        26.0|  6.1315413|\n",
      "|  16718|0446605239|          9|         2302.0|        26.0|   7.897742|\n",
      "|  31846|0446605239|          0|          700.0|        26.0| -1.8746053|\n",
      "|  56045|0446605239|          7|        17081.0|        26.0| -2.3354435|\n",
      "|  71490|0446605239|          7|         3978.0|        26.0|  7.4649453|\n",
      "|  53537|0446605239|          9|        19318.0|        26.0|  1.0867605|\n",
      "|  37736|0446605239|          0|        19160.0|        26.0|        0.0|\n",
      "|  65663|0446605239|         10|         1843.0|        26.0|    2.16429|\n",
      "|  56447|0446605239|          0|           88.0|        26.0| -0.7519628|\n",
      "|  73394|0446605239|          0|           35.0|        26.0| 0.14612348|\n",
      "|  70666|0446605239|          5|         1513.0|        26.0|   7.023949|\n",
      "+-------+----------+-----------+---------------+------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "predictions=model.transform(test_data)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e692a2c8-56fc-4f83-9862-258bb3595fb7",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255cb2c8-ed43-42f3-82e8-3e64a8c309af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:53:43 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:43 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:44 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:48 WARN DAGScheduler: Broadcasting large task binary with size 4.3 MiB\n",
      "24/11/05 18:53:49 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n",
      "[Stage 180:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.647512858879087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:53:52 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator=RegressionEvaluator(metricName=\"rmse\",labelCol=\"Book-Rating\",predictionCol=\"prediction\")\n",
    "rmse=evaluator.evaluate(predictions)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ee3fb07-ef3b-4b87-887d-512613cde4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:53:52 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----------+---------------+------------+\n",
      "|User-ID|      ISBN|Book-Rating|User-ID-numeric|ISBN-numeric|\n",
      "+-------+----------+-----------+---------------+------------+\n",
      "|      8|0002005018|          5|         7987.0|     10774.0|\n",
      "|      8|0399135782|          0|         7987.0|      3757.0|\n",
      "|      8|0671870432|          0|         7987.0|     72648.0|\n",
      "|      8|0679425608|          0|         7987.0|    224228.0|\n",
      "|      8|080652121X|          0|         7987.0|    248065.0|\n",
      "|      8|0887841740|          5|         7987.0|    125246.0|\n",
      "|      8|1552041778|          5|         7987.0|    278428.0|\n",
      "|      8|1881320189|          7|         7987.0|     80389.0|\n",
      "|      9|0452264464|          6|        33336.0|       247.0|\n",
      "|     10|1841721522|          0|        33615.0|      3302.0|\n",
      "|     10|8477024456|          6|        33615.0|    327212.0|\n",
      "|     14|0689821166|          6|        23468.0|    228448.0|\n",
      "|     14|0971880107|          0|        23468.0|         0.0|\n",
      "|     16|0345402871|          9|        36526.0|       183.0|\n",
      "|     17|0312978383|          0|        16147.0|       793.0|\n",
      "|     17|0553264990|          5|        16147.0|     12468.0|\n",
      "|     17|0553278398|          0|        16147.0|      1895.0|\n",
      "|     19|0375759778|          7|        67074.0|      4890.0|\n",
      "|     22|3442353866|          0|        24796.0|    136106.0|\n",
      "|     22|3442410665|          0|        24796.0|     81478.0|\n",
      "+-------+----------+-----------+---------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "26241795-7f50-4575-9bc4-83abf3b937b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:53:53 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:54 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:55 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+\n",
      "|User-ID-numeric|ISBN-numeric|Book-Rating|\n",
      "+---------------+------------+-----------+\n",
      "|        17055.0|     16226.0|          3|\n",
      "|        17055.0|    274193.0|          0|\n",
      "|        17055.0|    127259.0|          0|\n",
      "+---------------+------------+-----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "user1=test_data.filter(test_data['user-ID']==53).select(['User-ID-numeric','ISBN-numeric','Book-Rating'])\n",
    "user1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cec9f152-95c2-49f3-9b93-ceecc10209ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:53:55 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:57 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:53:57 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:54:01 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n",
      "24/11/05 18:54:02 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n",
      "[Stage 265:>                                                        (0 + 8) / 8]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------+-----------+----------+\n",
      "|User-ID-numeric|ISBN-numeric|Book-Rating|prediction|\n",
      "+---------------+------------+-----------+----------+\n",
      "|        17055.0|     16226.0|          3| 6.2307205|\n",
      "|        17055.0|    127259.0|          0| 1.8423612|\n",
      "+---------------+------------+-----------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "recommendations = model.transform(user1) \n",
    "\n",
    "recommendations.orderBy('prediction',ascending=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b535f8e-4686-4f3d-af1d-65b6dc4c4294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/05 18:54:05 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:54:05 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:54:06 WARN DAGScheduler: Broadcasting large task binary with size 13.7 MiB\n",
      "24/11/05 18:54:10 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n",
      "24/11/05 18:54:11 WARN DAGScheduler: Broadcasting large task binary with size 13.8 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|      ISBN|          Book-Title|         Book-Author|Year-Of-Publication|           Publisher|         Image-URL-S|         Image-URL-M|         Image-URL-L|prediction|\n",
      "+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|0373706669|As Years Go By (S...| Margaret Chittenden|               1995|           Harlequin|http://images.ama...|http://images.ama...|http://images.ama...| 5.6228933|\n",
      "|0373165218|Baby On The Doors...|Cathy Gillen Thacker|               1994|           Harlequin|http://images.ama...|http://images.ama...|http://images.ama...|  5.494483|\n",
      "|0671042858|The Girl Who Love...|        Stephen King|               2000|              Pocket|http://images.ama...|http://images.ama...|http://images.ama...| 2.0202131|\n",
      "|0440213525|          The Client|        John Grisham|               1994|Dell Publishing C...|http://images.ama...|http://images.ama...|http://images.ama...| 1.9838008|\n",
      "|044021145X|            The Firm|        John Grisham|               1992|Bantam Dell Publi...|http://images.ama...|http://images.ama...|http://images.ama...| 1.8891459|\n",
      "|0446364193|Along Came a Spid...|     James Patterson|               1993|        Warner Books|http://images.ama...|http://images.ama...|http://images.ama...| 1.5836711|\n",
      "|0446603589|      Absolute Power|      David Baldacci|               1996|        Warner Books|http://images.ama...|http://images.ama...|http://images.ama...| 1.5831767|\n",
      "|067100042X|Silent Night : A ...|  Mary Higgins Clark|               1996|              Pocket|http://images.ama...|http://images.ama...|http://images.ama...| 1.5187869|\n",
      "|0380710722|It's Always Somet...|        Gilda Radner|               1990|                Avon|http://images.ama...|http://images.ama...|http://images.ama...| 1.4264795|\n",
      "|0671729403|Fallen Hearts (Ca...|        V.C. Andrews|               1990|              Pocket|http://images.ama...|http://images.ama...|http://images.ama...| 1.2358987|\n",
      "+----------+--------------------+--------------------+-------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "books_df=spark.read.options(delimiter=\";\", header=True, inferSchema=True).csv(\"books.csv\")\n",
    "\n",
    "def recommend_for_user(user_id, n):\n",
    "    ratings_user = rating_df.filter(col('User-Id')==user_id)\n",
    "    #getting books where rating is still zero or zero interaction\n",
    "    pred_ratings_user = model.transform(ratings_user.filter(col('Book-Rating')==0))\n",
    "    recs_user = books_df.join(pred_ratings_user.select(['ISBN', 'prediction']), on='ISBN')\n",
    "    recs_user = recs_user.sort('prediction', ascending=False).limit(10)\n",
    "    # recs_user = recs_user.sort('prediction', ascending=False).drop('prediction').limit(10)\n",
    "    return recs_user\n",
    "recs_user = recommend_for_user(31987, 7)\n",
    "recs_user.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8c8b1-f77e-4d1f-96be-963a300040a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d181365-7c22-437d-b9d4-86b99289b9e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
